// src/tenant/tenant-datasource.service.ts
import {
  Injectable,
  OnModuleDestroy,
  Logger,
  NotFoundException,
} from '@nestjs/common';
import { DataSource } from 'typeorm';
import { getTenantDbConfig } from './getTenantDbConfig';
import { InjectDataSource } from '@nestjs/typeorm';
import { Store } from '../../../entities/global/store.entity';

interface CachedDataSource {
  dataSource: DataSource;
  lastAccessed: Date;
  accessCount: number;
}

@Injectable()
export class TenantDataSourceService implements OnModuleDestroy {
  private readonly logger = new Logger(TenantDataSourceService.name);
  private tenantDataSources = new Map<string, CachedDataSource>();
  private initializingDataSources = new Map<string, Promise<DataSource>>();
  private cleanupInterval!: NodeJS.Timeout;

  // Configuration
  private readonly MAX_CACHED_CONNECTIONS = 50;
  private readonly CONNECTION_IDLE_TIMEOUT = 30 * 60 * 1000; // 30 minutes
  private readonly CLEANUP_INTERVAL = 5 * 60 * 1000; // 5 minutes

  constructor(
    @InjectDataSource('globalConnection')
    private globalDataSource: DataSource,
  ) {
    // Kh·ªüi t·∫°o cleanup job ƒë·ªÉ ƒë√≥ng c√°c connection kh√¥ng s·ª≠ d·ª•ng
    this.startCleanupJob();
  }

  /**
   * L·∫•y ho·∫∑c t·∫°o DataSource cho m·ªôt c·ª≠a h√†ng c·ª• th·ªÉ v·ªõi caching v√† validation
   */
  async getTenantDataSource(storeId: string): Promise<DataSource> {
    storeId = storeId.trim();
    if (!storeId) {
      throw new Error('Store ID cannot be empty');
    }

    try {
      // 1. Validate v√† l·∫•y th√¥ng tin store t·ª´ Global Database
      const store = await this.getValidatedStore(storeId);

      const dbName = store.databaseName;

      // 2. Ki·ªÉm tra cache
      if (this.hasCachedDataSource(dbName)) {
        this.updateAccessInfo(dbName);
        this.logger.debug(
          `Returning cached DataSource for store: ${storeId} (db: ${dbName})`,
        );
        return this.tenantDataSources.get(dbName)!.dataSource;
      }

      // 3. Ki·ªÉm tra DataSource ƒëang ƒë∆∞·ª£c kh·ªüi t·∫°o
      if (this.initializingDataSources.has(dbName)) {
        this.logger.debug(
          `Waiting for DataSource initialization: ${storeId} (db: ${dbName})`,
        );
        return await this.initializingDataSources.get(dbName)!;
      }

      // 4. Kh·ªüi t·∫°o DataSource m·ªõi
      return await this.initializeNewDataSource(storeId, dbName);
    } catch (error) {
      this.logger.error(
        `Failed to get tenant DataSource for store: ${storeId}`,
        error instanceof Error ? error.stack : String(error),
      );
      throw error;
    }
  }

  /**
   * Validate store v√† ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán business
   */
  private async getValidatedStore(storeId: string): Promise<Store> {
    const storeRepo = this.globalDataSource.getRepository(Store);
    const store = await storeRepo.findOne({
      where: {
        storeId,
        isActive: true, // Ch·ªâ l·∫•y store ƒëang active
        isDeleted: false, // Kh√¥ng b·ªã soft delete
      },
    });
    if (!store) {
      this.logger.warn(
        `Attempted to access non-existent or inactive store: ${storeId}`,
      );
      throw new NotFoundException(
        `Store with ID ${storeId} not found or inactive`,
      );
    }

    if (!store.databaseName.trim()) {
      this.logger.error(`Store ${storeId} has no database name configured`);
      throw new Error(`Store ${storeId} has invalid database configuration`);
    }

    return store;
  }

  /**
   * Ki·ªÉm tra xem c√≥ cached DataSource h·ª£p l·ªá kh√¥ng
   */
  private hasCachedDataSource(dbName: string): boolean {
    const cached = this.tenantDataSources.get(dbName);
    return cached?.dataSource.isInitialized === true;
  }

  /**
   * C·∫≠p nh·∫≠t th√¥ng tin truy c·∫≠p cho cached DataSource
   */
  private updateAccessInfo(dbName: string): void {
    const cached = this.tenantDataSources.get(dbName);
    if (cached) {
      cached.lastAccessed = new Date();
      cached.accessCount++;
    }
  }

  /**
   * Kh·ªüi t·∫°o DataSource m·ªõi v·ªõi proper error handling
   */
  private async initializeNewDataSource(
    storeId: string,
    dbName: string,
  ): Promise<DataSource> {
    // Ki·ªÉm tra gi·ªõi h·∫°n s·ªë l∆∞·ª£ng connection
    if (this.tenantDataSources.size >= this.MAX_CACHED_CONNECTIONS) {
      await this.cleanupOldestConnections();
    }

    const initPromise = this.createDataSourceInitPromise(storeId, dbName);
    this.initializingDataSources.set(dbName, initPromise);

    try {
      const dataSource = await initPromise;

      // Cache DataSource v·ªõi metadata
      this.tenantDataSources.set(dbName, {
        dataSource,
        lastAccessed: new Date(),
        accessCount: 1,
      });

      this.logger.log(
        `Tenant DataSource initialized successfully for store: ${storeId} (db: ${dbName})`,
      );
      return dataSource;
    } finally {
      this.initializingDataSources.delete(dbName);
    }
  }

  /**
   * T·∫°o Promise ƒë·ªÉ kh·ªüi t·∫°o DataSource
   */
  // private async createDataSourceInitPromise(
  //   storeId: string,
  //   dbName: string,
  // ): Promise<DataSource> {
  //   this.logger.log(
  //     `Initializing new DataSource for store: ${storeId} (db: ${dbName})`,
  //   );

  //   const tenantConfig = getTenantDbConfig(dbName);
  //   const newDataSource = new DataSource(tenantConfig);

  //   try {
  //     await newDataSource.initialize();

  //     // Test connection
  //     const shouldSync = await this.shouldSynchronize(newDataSource);
  //     if (shouldSync) {
  //       this.logger.warn(`Synchronizing schema for db: ${dbName}`);
  //       await newDataSource.synchronize();
  //     }

  //     return newDataSource;
  //   } catch (error) {
  //     this.logger.error(
  //       `Failed to initialize DataSource for store: ${storeId} (db: ${dbName})`,
  //       error instanceof Error ? error.message : String(error),
  //     );

  //     // Cleanup n·∫øu initialization th·∫•t b·∫°i
  //     if (newDataSource.isInitialized) {
  //       try {
  //         await newDataSource.destroy();
  //       } catch (destroyError) {
  //         this.logger.error(
  //           'Failed to cleanup failed DataSource',
  //           destroyError,
  //         );
  //       }
  //     }

  //     throw error;
  //   }
  // }

  private async createDataSourceInitPromise(
    storeId: string,
    schemaName: string,
  ): Promise<DataSource> {
    this.logger.log(
      `Initializing new DataSource for store: ${storeId} (schema: ${schemaName})`,
    );

    // üîß B∆∞·ªõc 1: Ensure schema exists
    await this.ensureSchemaExists(schemaName);

    // üîß B∆∞·ªõc 2: Chu·∫©n b·ªã config
    const tenantConfig = getTenantDbConfig(schemaName);
    const newDataSource = new DataSource(tenantConfig);

    try {
      await newDataSource.initialize();

      // üîç B∆∞·ªõc 3: Ki·ªÉm tra c√≥ c·∫ßn sync kh√¥ng
      const shouldSync = await this.shouldSynchronize(newDataSource);
      if (shouldSync) {
        this.logger.warn(`Synchronizing schema for: ${schemaName}`);
        await newDataSource.synchronize();
      }

      return newDataSource;
    } catch (error) {
      this.logger.error(
        `‚ùå Failed to initialize DataSource for store: ${storeId} (schema: ${schemaName})`,
        error instanceof Error ? error.message : String(error),
      );

      if (newDataSource.isInitialized) {
        try {
          await newDataSource.destroy();
        } catch (destroyError) {
          this.logger.error(
            'Failed to cleanup failed DataSource',
            destroyError,
          );
        }
      }

      throw error;
    }
  }

  private async ensureSchemaExists(schemaName: string): Promise<void> {
    try {
      await this.globalDataSource.query(
        `CREATE SCHEMA IF NOT EXISTS "${schemaName}";`,
      );
      this.logger.log(`‚úÖ Schema ensured: ${schemaName}`);
    } catch (err) {
      this.logger.error(`‚ùå Failed to ensure schema: ${schemaName}`, err);
      throw new Error(`Kh√¥ng th·ªÉ t·∫°o schema cho tenant: ${schemaName}`);
    }
  }

  /**
   * Ki·ªÉm tra xem c√≥ c·∫ßn ƒë·ªìng b·ªô h√≥a schema kh√¥ng
   * N·∫øu b·∫£ng 'products' kh√¥ng t·ªìn t·∫°i, s·∫Ω ƒë·ªìng b·ªô h√≥a schema
   */
  /**
   * Ki·ªÉm tra xem c√≥ c·∫ßn ƒë·ªìng b·ªô h√≥a schema kh√¥ng
   * N·∫øu b·∫£ng 'products' kh√¥ng t·ªìn t·∫°i, s·∫Ω ƒë·ªìng b·ªô h√≥a schema
   */
  private async shouldSynchronize(dataSource: DataSource): Promise<boolean> {
    try {
      // Check TypeORM migrations table
      const result: unknown = await dataSource.query(`
      SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = 'migrations'
      ) as "exists"
    `);

      // Type guard for result validation
      const isValidExistsResult = (
        data: unknown,
      ): data is Array<{ exists: boolean }> => {
        return (
          Array.isArray(data) &&
          data.length > 0 &&
          typeof data[0] === 'object' &&
          data[0] !== null &&
          'exists' in data[0] &&
          typeof (data[0] as Record<string, unknown>).exists === 'boolean'
        );
      };

      if (!isValidExistsResult(result) || !result[0].exists) {
        return true; // Ch∆∞a c√≥ migration table ‚Üí DB m·ªõi
      }

      // Optional: Check migration status
      const migrationCountResult: unknown = await dataSource.query(`
      SELECT COUNT(*) as count FROM migrations
    `);

      // Type guard for count result validation
      const isValidCountResult = (
        data: unknown,
      ): data is Array<{ count: string }> => {
        return (
          Array.isArray(data) &&
          data.length > 0 &&
          typeof data[0] === 'object' &&
          data[0] !== null &&
          'count' in data[0] &&
          typeof (data[0] as Record<string, unknown>).count === 'string'
        );
      };

      if (!isValidCountResult(migrationCountResult)) {
        return true; // Default to sync if can't determine migration count
      }

      return parseInt(migrationCountResult[0].count, 10) === 0; // Ch∆∞a c√≥ migration n√†o
    } catch (err) {
      this.logger.warn('Migration check failed. Defaulting to sync.', err);
      return true;
    }
  }

  /**
   * D·ªçn d·∫πp c√°c connection c≈© nh·∫•t khi ƒë·∫°t gi·ªõi h·∫°n
   */
  private async cleanupOldestConnections(): Promise<void> {
    const sortedEntries = Array.from(this.tenantDataSources.entries()).sort(
      ([, a], [, b]) => a.lastAccessed.getTime() - b.lastAccessed.getTime(),
    );

    const toRemove = sortedEntries.slice(
      0,
      Math.floor(this.MAX_CACHED_CONNECTIONS * 0.2),
    );

    for (const [dbName] of toRemove) {
      await this.closeTenantDataSource(dbName);
    }
  }

  /**
   * ƒê√≥ng DataSource c·ª• th·ªÉ
   */
  async closeTenantDataSource(dbName: string): Promise<void> {
    const cached = this.tenantDataSources.get(dbName);
    if (!cached) return;

    try {
      if (cached.dataSource.isInitialized) {
        await cached.dataSource.destroy();
        this.logger.log(`Tenant DataSource destroyed: ${dbName}`);
      }
    } catch (error) {
      this.logger.error(`Error destroying DataSource ${dbName}:`, error);
    } finally {
      this.tenantDataSources.delete(dbName);
    }
  }

  /**
   * B·∫Øt ƒë·∫ßu cleanup job ƒë·ªÉ d·ªçn d·∫πp c√°c connection idle
   */
  private startCleanupJob(): void {
    this.cleanupInterval = setInterval(() => {
      this.cleanupIdleConnections().catch((err) => {
        this.logger.error('Cleanup job failed:', err);
      });
    }, this.CLEANUP_INTERVAL);
  }

  /**
   * D·ªçn d·∫πp c√°c connection kh√¥ng s·ª≠ d·ª•ng l√¢u
   */
  private async cleanupIdleConnections(): Promise<void> {
    const now = new Date();
    const toCleanup: string[] = [];

    for (const [dbName, cached] of this.tenantDataSources.entries()) {
      const idleTime = now.getTime() - cached.lastAccessed.getTime();
      if (idleTime > this.CONNECTION_IDLE_TIMEOUT) {
        toCleanup.push(dbName);
      }
    }

    if (toCleanup.length > 0) {
      this.logger.log(
        `Cleaning up ${toCleanup.length} idle tenant connections`,
      );
      for (const dbName of toCleanup) {
        await this.closeTenantDataSource(dbName);
      }
    }
  }

  /**
   * L·∫•y th·ªëng k√™ v·ªÅ c√°c DataSource ƒëang cache
   */
  getConnectionStats(): {
    totalConnections: number;
    initializingConnections: number;
    connectionDetails: Array<{
      dbName: string;
      lastAccessed: Date;
      accessCount: number;
      isInitialized: boolean;
    }>;
  } {
    return {
      totalConnections: this.tenantDataSources.size,
      initializingConnections: this.initializingDataSources.size,
      connectionDetails: Array.from(this.tenantDataSources.entries()).map(
        ([dbName, cached]) => ({
          dbName,
          lastAccessed: cached.lastAccessed,
          accessCount: cached.accessCount,
          isInitialized: cached.dataSource.isInitialized,
        }),
      ),
    };
  }

  /**
   * ƒê√≥ng t·∫•t c·∫£ connections khi app shutdown
   */
  async onModuleDestroy(): Promise<void> {
    this.logger.log(
      'Destroying all tenant DataSources on application shutdown...',
    );

    // D·ª´ng cleanup job
    clearInterval(this.cleanupInterval);

    // ƒê√≥ng t·∫•t c·∫£ DataSources
    const closePromises: Promise<void>[] = [];

    for (const [dbName, cached] of this.tenantDataSources.entries()) {
      if (cached.dataSource.isInitialized) {
        closePromises.push(
          cached.dataSource.destroy().catch((error) => {
            this.logger.error(`Error destroying DataSource ${dbName}:`, error);
          }),
        );
      }
    }

    await Promise.all(closePromises);

    this.tenantDataSources.clear();
    this.initializingDataSources.clear();

    this.logger.log('All tenant DataSources destroyed successfully');
  }
}
